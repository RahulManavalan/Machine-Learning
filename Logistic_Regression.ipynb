{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled27.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNii4nsQ7hSlrE08qz1BXUc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulManavalan/Machine-Learning/blob/master/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_ntdbwns98x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install tensorflow==1.0\n",
        "import pandas as pd \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPYdmOoytX-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_goog_sp500_data():\n",
        "  googFile = \"/content/GOOG.csv\"\n",
        "  spFile = \"/content/^IXIC.csv\"\n",
        "\n",
        "  goog = pd.read_csv(googFile,sep=\",\",usecols=[0,5],names=[\"Date\",\"Goog\"],header=0)\n",
        "  sp = pd.read_csv(spFile,sep=\",\",usecols=[0,5],names=[\"Date\",\"SP500\"],header=0)\n",
        "\n",
        "\n",
        "  goog[\"SP500\"] = sp[\"SP500\"]\n",
        "\n",
        "  goog[\"Date\"] = pd.to_datetime(goog[\"Date\"],format=\"%Y-%m-%d\")\n",
        "  goog = goog.sort_values([\"Date\"],ascending=[True])\n",
        "\n",
        "  returns = goog[[key for key in dict(goog.dtypes) if dict(goog.dtypes)[key] in [\"float64\",\"int64\"]]].pct_change()\n",
        "\n",
        "  return returns "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-2yiTgNycS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_goog_sp500_logistic_data():\n",
        "  returns = read_goog_sp500_data() \n",
        "  returns[\"Intercept\"] = 1 \n",
        "  xData = np.array(returns[[\"SP500\",\"Intercept\"]][1:-1])\n",
        "  yData = (returns[\"Goog\"] > 0)[1:-1] \n",
        "  return (xData , yData) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DNCu7VM4h8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "xData , yData = read_goog_sp500_logistic_data() \n",
        "\n",
        "W = tf.Variable(tf.ones([1,2]) , name = \"W\") \n",
        "b = tf.Variable(tf.zeros([2]), name = \"b\")\n",
        "\n",
        "x = tf.placeholder(tf.float32 , [None,1] , name=\"x\")\n",
        "y_ = tf.placeholder(tf.float32 , [None,2] , name=\"y_\")\n",
        "\n",
        "y = tf.matmul(x,W) + b\n",
        "\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_ , logits = y))\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9HeOjX2CfQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_xs = np.expand_dims(xData[:,0],axis=1) \n",
        "all_ys = np.array([([1,0] if yEl == True else [0,1]) for yEl in yData])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vad4a-JODw-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_size = len(all_xs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfhryV0hD5de",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainWithMultiplePointsperEpoch(steps,train,batch_size): \n",
        "  init = tf.global_variables_initializer() \n",
        "\n",
        "  with tf.Session() as sess: \n",
        "    sess.run(init) \n",
        "\n",
        "    for i in range(steps): \n",
        "      if dataset_size == batch_size: \n",
        "        batch_start_idx = 0 \n",
        "      elif dataset_size < batch_size: \n",
        "        raise ValueError(\"The batch size must be smaller than the size of the dataset\")\n",
        "      else : \n",
        "        batch_start_idx = (i * batch_size) % (dataset_size)\n",
        "\n",
        "      batch_end_idx = batch_start_idx + batch_size \n",
        "\n",
        "      batch_xs = all_xs[batch_start_idx : batch_end_idx] \n",
        "      batch_ys = all_ys[batch_start_idx : batch_end_idx]\n",
        "\n",
        "      feed = {x : batch_xs , y_ : batch_ys} \n",
        "      sess.run(train, feed_dict = feed)\n",
        "\n",
        "      if (i+1)%1000 == 0 : \n",
        "        print(\"After %d iterations:\" %i) \n",
        "        print(sess.run(W))\n",
        "        print(sess.run(b))\n",
        "\n",
        "        print(\"Cross Entropy : %f\" %sess.run(cross_entropy , feed_dict = feed))\n",
        "\n",
        "    correct_prediction = tf.equal(tf.argmax(y_,1) , tf.argmax(y,1))\n",
        "\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))\n",
        "    print(\"Accuracy: %f \" %sess.run(accuracy , feed_dict = {x: all_xs , y_:all_ys} ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-UpzY-rI-nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainWithMultiplePointsperEpoch(20000,train_step,dataset_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO6Mtey6J6cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}