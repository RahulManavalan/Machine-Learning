{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPO6MaMOZVlVzujw0VsIYCa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulManavalan/Machine-Learning/blob/master/Linear_regression_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq3D_Daiwlfz",
        "colab_type": "code",
        "outputId": "f218e047-d5ab-45bd-910a-1a8fed488c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "pip install tensorflow==1.0"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0) (1.18.4)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0) (0.34.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->tensorflow==1.0) (46.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dF4jkLYwuQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG6jNVRnwyYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_goog_sp500_data():\n",
        "  googFile = \"/GOOG.csv\"\n",
        "  spFile = \"/content/^IXIC.csv\"\n",
        "\n",
        "  goog = pd.read_csv(googFile,sep=\",\",usecols=[0,5],names=[\"Date\",\"Goog\"],header=0)\n",
        "  sp = pd.read_csv(spFile,sep=\",\",usecols=[0,5],names=[\"Date\",\"SP500\"],header=0)\n",
        "\n",
        "\n",
        "  goog[\"SP500\"] = sp[\"SP500\"]\n",
        "\n",
        "  goog[\"Date\"] = pd.to_datetime(goog[\"Date\"],format=\"%Y-%m-%d\")\n",
        "  goog = goog.sort_values([\"Date\"],ascending=[True])\n",
        "\n",
        "  returns = goog[[key for key in dict(goog.dtypes) if dict(goog.dtypes)[key] in [\"float64\",\"int64\"]]].pct_change() \n",
        "\n",
        "  xData = np.array(returns[\"SP500\"])[1:]\n",
        "  yData = np.array(returns[\"Goog\"])[1:]\n",
        "\n",
        "  return(xData,yData) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YwHGFNjw_TE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xData , yData = read_goog_sp500_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gfRczcMy-pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk5ymoSezEVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.zeros([1,1]))\n",
        "b = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "x = tf.placeholder(tf.float32,[None,1])\n",
        "Wx = tf.matmul(x,W) \n",
        "y = Wx + b \n",
        "\n",
        "W_hist = tf.summary.histogram(\"weights\",W)\n",
        "b_hist = tf.summary.histogram(\"biases\",b) \n",
        "y_hist = tf.summary.histogram(\"y\" , y) \n",
        "y_ = tf.placeholder(tf.float32 , [None,1]) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpXwWmyyzxzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost = tf.reduce_mean(tf.square(y - y_))\n",
        "cost_hist = tf.summary.histogram(\"cost\",cost)\n",
        "train_step_adagrad = tf.train.FtrlOptimizer(1).minimize(cost) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luqEyBIR0PCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainwithoneEpoch(steps,train_step): \n",
        "  init = tf.global_variables_initializer() \n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init) \n",
        "    merged_summary = tf.summary.merge_all() \n",
        "    writer = tf.summary.FileWriter(\"./linear_regression_demo1\",sess.graph)\n",
        "\n",
        "    for i in range(steps): \n",
        "      xs = np.array([[xData[i%len(xData)]]])\n",
        "      ys = np.array([[yData[i%len(yData)]]])\n",
        "\n",
        "      feed = {x:xs , y_:ys}\n",
        "\n",
        "      sess.run(train_step,feed_dict=feed)\n",
        "      result = sess.run(merged_summary,feed_dict=feed) \n",
        "      writer.add_summary(result,i) \n",
        "\n",
        " \n",
        "      if (i+1)%1000 == 0 : \n",
        "        print(\"After %d iterations :\" %i)\n",
        "\n",
        "        print(\"W %f\" % sess.run(W) )\n",
        "        print(\"b %f\" % sess.run(b) )\n",
        "\n",
        "        print(\"Cost function %f\" % sess.run(cost,feed_dict=feed))\n",
        "\n",
        "        writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afpal2P_8QFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_size = len(xData) \n",
        "def trainwithMultiplePointsperEpoch(steps,train_step,batch_size):\n",
        "  init = tf.global_variables_initializer() \n",
        "  with tf.Session() as sess: \n",
        "    sess.run(init) \n",
        "    merged_summary = tf.summary.merge_all() \n",
        "    writer = tf.summary.FileWriter(\"./linear_regression_demo2\",sess.graph)\n",
        "\n",
        "    for i in range(steps):\n",
        "      if data_size == batch_size:\n",
        "        batch_size_idx = 0 \n",
        "      elif data_size < batch_size:\n",
        "        raise ValueError(\"dataset_size must be greater than the batch size\")\n",
        "      else : \n",
        "        batch_size_idx = (i*batch_size)%(data_size)\n",
        "      batch_end_idx = batch_size_idx + batch_size \n",
        "\n",
        "      batch_xs = xData[batch_size_idx:batch_end_idx] \n",
        "      batch_ys = yData[batch_size_idx:batch_end_idx]\n",
        "\n",
        "      feed = {x:batch_xs.reshape(-1,1) , y_:batch_ys.reshape(-1,1)}\n",
        "      sess.run(train_step , feed_dict=feed)\n",
        "\n",
        "      #result = sess.run(merged_summary,feed_dict=feed) \n",
        "      #writer.add_summary(result,i) \n",
        "\n",
        " \n",
        "      if (i+1)%1000 == 0 : \n",
        "        print(\"After %d iterations :\" %i)\n",
        "\n",
        "        print(\"W %f\" % sess.run(W) )\n",
        "        print(\"b %f\" % sess.run(b) )\n",
        "\n",
        "        print(\"Cost function %f\" % sess.run(cost,feed_dict=feed))\n",
        "\n",
        "        writer.close()\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvcdeltD4MNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "8ab5f4e9-9060-40f4-e962-c6119b8f04c6"
      },
      "source": [
        "trainwithMultiplePointsperEpoch(5000,train_step_adagrad,len(xData))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 999 iterations :\n",
            "W 1.013051\n",
            "b 0.004040\n",
            "Cost function 0.003492\n",
            "After 1999 iterations :\n",
            "W 1.013051\n",
            "b 0.004040\n",
            "Cost function 0.003492\n",
            "After 2999 iterations :\n",
            "W 1.013051\n",
            "b 0.004040\n",
            "Cost function 0.003492\n",
            "After 3999 iterations :\n",
            "W 1.013051\n",
            "b 0.004040\n",
            "Cost function 0.003492\n",
            "After 4999 iterations :\n",
            "W 1.013051\n",
            "b 0.004040\n",
            "Cost function 0.003492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8TpCVBb63Xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}